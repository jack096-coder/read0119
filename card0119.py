import streamlit as st
from streamlit_cropper import st_cropper
from PIL import Image
import numpy as np
import cv2
import pandas as pd
import io

# --- å½±åƒè™•ç†å‡½æ•¸å€åŸŸ (OpenCV) ---
# é€™äº›å‡½æ•¸ä¿æŒä¸è®Šï¼Œè² è²¬åº•å±¤çš„è¦–è¦ºè¾¨è­˜

def detect_corner_markers(img_crop_bgr):
    """è¾¨è­˜é»‘è‰²æ–¹å½¢å®šä½é» (A1)"""
    if img_crop_bgr.size == 0: return []
    gray = cv2.cvtColor(img_crop_bgr, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY_INV)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    detected_squares = []
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area < 50: continue
        epsilon = 0.04 * cv2.arcLength(cnt, True)
        approx = cv2.approxPolyDP(cnt, epsilon, True)
        if len(approx) == 4:
            points = approx.reshape(4, 2).tolist()
            detected_squares.append(points)
    return detected_squares

def detect_bubbles(img_crop_bgr):
    """è¾¨è­˜åœ“å½¢æ°£æ³¡ (A2, A3)"""
    if img_crop_bgr.size == 0: return []
    gray = cv2.cvtColor(img_crop_bgr, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (9, 9), 2)
    
    circles = cv2.HoughCircles(
        blurred, 
        cv2.HOUGH_GRADIENT, 
        dp=1.2, 
        minDist=15,    
        param1=100,
        param2=25,     
        minRadius=8,   
        maxRadius=40
    )
    
    detected_circles = []
    if circles is not None:
        circles = np.uint16(np.around(circles))
        for i in circles[0, :]:
            detected_circles.append((int(i[0]), int(i[1]), int(i[2])))
    return detected_circles

def draw_results_on_image(pil_image, results, region_offsets):
    """å°‡è¾¨è­˜çµæœç•«åœ¨åŸå§‹åœ–ç‰‡ä¸Š"""
    img_cv = np.array(pil_image.convert('RGB'))
    img_cv = img_cv[:, :, ::-1].copy() 

    # ç¹ªè£½ A1 æ–¹å¡Š
    if 'A1_value' in results:
        offset_x, offset_y = region_offsets.get('A1', (0, 0))
        for square in results['A1_value']:
            abs_points = np.array(square) + [offset_x, offset_y]
            pts = abs_points.reshape((-1, 1, 2)).astype(np.int32)
            cv2.polylines(img_cv, [pts], True, (0, 0, 255), 3)

    # ç¹ªè£½ A2, A3 åœ“åœˆ
    for region_key in ['A2_value', 'A3_value']:
        if region_key in results:
            region_name = region_key.split('_')[0]
            offset_x, offset_y = region_offsets.get(region_name, (0, 0))
            for (cx, cy, r) in results[region_key]:
                abs_cx = cx + offset_x
                abs_cy = cy + offset_y
                cv2.rectangle(img_cv, (abs_cx - r, abs_cy - r), (abs_cx + r, abs_cy + r), (0, 0, 255), 2)

    return Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))


# --- Streamlit ä¸»ç¨‹å¼ ---

st.set_page_config(page_title="ç­”æ¡ˆå¡è¾¨è­˜ç³»çµ±", layout="wide")

# åˆå§‹åŒ– Session State
if 'img_file' not in st.session_state:
    st.session_state.img_file = None
if 'original_image' not in st.session_state:
    st.session_state.original_image = None
if 'resized_image' not in st.session_state:
    st.session_state.resized_image = None
if 'scale_factor' not in st.session_state:
    st.session_state.scale_factor = 1.0
if 'zones' not in st.session_state:
    st.session_state.zones = {'A1': None, 'A2': None, 'A3': None, 'A4': None}
if 'cropping_mode' not in st.session_state:
    st.session_state.cropping_mode = None
if 'recognition_results' not in st.session_state:
    st.session_state.recognition_results = {}
if 'result_image' not in st.session_state:
    st.session_state.result_image = None

st.title("ğŸ“ ç­”æ¡ˆå¡å…¨ç‰ˆæ¨™ç¤ºèˆ‡è¾¨è­˜ (ä¿®å¾©ç‰ˆ)")

col_left, col_right = st.columns([1, 2])

# --- å·¦å´æ¬„ä½ ---
with col_left:
    st.header("1. ä¸Šå‚³èˆ‡è¨­å®š")
    uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ç©ºç™½ç­”æ¡ˆå¡ (jpg, png)", type=["jpg", "png", "jpeg"])

    if uploaded_file:
        # ç•¶ä¸Šå‚³æ–°æª”æ¡ˆæ™‚é‡ç½®
        if st.session_state.img_file != uploaded_file:
            st.session_state.img_file = uploaded_file
            
            # 1. è®€å–åŸå§‹å¤§åœ–
            original_pil = Image.open(uploaded_file)
            st.session_state.original_image = original_pil
            
            # 2. è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹ï¼Œç”¢ç”Ÿé©åˆè¢å¹•çš„é è¦½åœ– (å¯¬åº¦è¨­ç‚º 800px)
            # é€™èƒ½è§£æ±ºã€Œç„¡æ³•é¡¯ç¤ºæ•´å¼µå¡ã€çš„å•é¡Œ
            display_width = 800
            w_percent = (display_width / float(original_pil.size[0]))
            h_size = int((float(original_pil.size[1]) * float(w_percent)))
            
            if original_pil.size[0] > display_width:
                st.session_state.resized_image = original_pil.resize((display_width, h_size), Image.Resampling.LANCZOS)
                st.session_state.scale_factor = 1 / w_percent 
            else:
                st.session_state.resized_image = original_pil
                st.session_state.scale_factor = 1.0

            # é‡ç½®å…¶ä»–ç‹€æ…‹
            st.session_state.zones = {'A1': None, 'A2': None, 'A3': None, 'A4': None}
            st.session_state.cropping_mode = None
            st.session_state.recognition_results = {}
            st.session_state.result_image = None
            
        st.success(f"åœ–ç‰‡å·²è¼‰å…¥ (ç¸®æ”¾å€ç‡: {st.session_state.scale_factor:.2f})")
        
        def set_crop_mode(mode):
            st.session_state.cropping_mode = mode

        # æŒ‰éˆ•å€
        st.markdown("### 2. æ¨™ç¤ºå€åŸŸ")
        st.info("è«‹ä¾åºé»æ“ŠæŒ‰éˆ•ï¼Œä¸¦åœ¨å³åœ–èª¿æ•´è—æ¡†ç¯„åœã€‚")

        b1, s1 = st.columns([3, 1])
        b1.button("æ¨™ç¤º A1 (å®šä½é»)", on_click=set_crop_mode, args=('A1',), use_container_width=True)
        if st.session_state.zones['A1']: s1.success("OK")
        
        b2, s2 = st.columns([3, 1])
        b2.button("æ¨™ç¤º A2 (åŸºæœ¬è³‡æ–™)", on_click=set_crop_mode, args=('A2',), use_container_width=True)
        if st.session_state.zones['A2']: s2.success("OK")

        b3, s3 = st.columns([3, 1])
        b3.button("æ¨™ç¤º A3 (é¸æ“‡é¡Œ)", on_click=set_crop_mode, args=('A3',), use_container_width=True)
        if st.session_state.zones['A3']: s3.success("OK")
        
        b4, s4 = st.columns([3, 1])
        b4.button("æ¨™ç¤º A4 (æ‰‹å¯«å€)", on_click=set_crop_mode, args=('A4',), use_container_width=True)
        if st.session_state.zones['A4']: s4.success("OK")

        st.markdown("---")
        
        # è¾¨è­˜æŒ‰éˆ•
        all_marked = all(st.session_state.zones.values())
        if st.button("é–‹å§‹è¾¨è­˜", disabled=not all_marked, type="primary", use_container_width=True):
            if st.session_state.original_image:
                with st.spinner("è¾¨è­˜ä¸­..."):
                    try:
                        results = {}
                        region_offsets = {}
                        scale = st.session_state.scale_factor
                        
                        full_img_cv = cv2.cvtColor(np.array(st.session_state.original_image.convert('RGB')), cv2.COLOR_RGB2BGR)
                        
                        # è¿´åœˆè™•ç†å„å€åŸŸ
                        for zone_key in ['A1', 'A2', 'A3']:
                            box = st.session_state.zones[zone_key]
                            
                            # é—œéµä¿®æ­£ï¼šé€™è£¡çš„ box ç¾åœ¨æ˜¯ dictionaryï¼Œå¯ä»¥å®‰å…¨è®€å–
                            real_left = int(box['left'] * scale)
                            real_top = int(box['top'] * scale)
                            real_width = int(box['width'] * scale)
                            real_height = int(box['height'] * scale)
                            
                            # é‚Šç•Œæª¢æŸ¥ (é¿å…è£åˆ‡è¶…å‡ºåœ–ç‰‡ç¯„åœ)
                            real_left = max(0, real_left)
                            real_top = max(0, real_top)
                            
                            # è£åˆ‡åŸåœ–
                            crop = full_img_cv[real_top:real_top+real_height, real_left:real_left+real_width]
                            
                            if zone_key == 'A1':
                                results['A1_value'] = detect_corner_markers(crop)
                            else:
                                results[f'{zone_key}_value'] = detect_bubbles(crop)
                                
                            region_offsets[zone_key] = (real_left, real_top)

                        # A4 (æ‰‹å¯«å€åº§æ¨™)
                        box_a4 = st.session_state.zones['A4']
                        real_left = int(box_a4['left'] * scale)
                        real_top = int(box_a4['top'] * scale)
                        real_width = int(box_a4['width'] * scale)
                        real_height = int(box_a4['height'] * scale)
                        
                        results['A4_value'] = [
                            (real_left, real_top),
                            (real_left + real_width, real_top + real_height)
                        ]

                        st.session_state.recognition_results = results
                        st.session_state.result_image = draw_results_on_image(st.session_state.original_image, results, region_offsets)
                        st.session_state.cropping_mode = None 
                        st.success("è¾¨è­˜å®Œæˆï¼")
                        
                    except Exception as e:
                        st.error(f"ç¨‹å¼ç™¼ç”ŸéŒ¯èª¤: {e}")
                        # å°å‡ºè©³ç´°éŒ¯èª¤ä»¥ä¾¿é™¤éŒ¯
                        import traceback
                        st.text(traceback.format_exc())

        # ä¸‹è¼‰æŒ‰éˆ•
        if st.session_state.recognition_results:
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # å»ºç«‹ A1 Sheet
                a1_data = []
                for i, square in enumerate(st.session_state.recognition_results.get('A1_value', [])):
                    row = {'ID': i+1}
                    for j, pt in enumerate(square):
                        row[f'Corner_{j+1}_X'] = pt[0]
                        row[f'Corner_{j+1}_Y'] = pt[1]
                    a1_data.append(row)
                if a1_data:
                    pd.DataFrame(a1_data).to_excel(writer, sheet_name='A1_Pos', index=False)

                # å»ºç«‹ A2, A3 Sheet
                for key in ['A2_value', 'A3_value']:
                    data = [{'ID': i+1, 'X': c[0], 'Y': c[1], 'R': c[2]} for i, c in enumerate(st.session_state.recognition_results.get(key, []))]
                    if data:
                        pd.DataFrame(data).to_excel(writer, sheet_name=key.split('_')[0], index=False)
                    
            output.seek(0)
            st.download_button("ä¸‹è¼‰ Excel çµæœ", data=output, file_name="omr_results.xlsx")

# --- å³å´æ¬„ä½ï¼šæ“ä½œå€ ---
with col_right:
    if st.session_state.original_image is None:
        st.info("ğŸ‘ˆ è«‹å…ˆå¾å·¦å´ä¸Šå‚³åœ–ç‰‡")
    else:
        current_mode = st.session_state.cropping_mode
        
        # æƒ…æ³ 1: æ¨™ç¤ºæ¨¡å¼
        if current_mode in ['A1', 'A2', 'A3', 'A4']:
            st.warning(f"ğŸ”§ æ­£åœ¨è¨­å®šï¼š{current_mode} å€åŸŸ")
            
            # å–å¾—è©²å€åŸŸç›®å‰çš„è¨­å®šå€¼
            default_box = st.session_state.zones.get(current_mode)
            default_coords = None
            
            # ç¢ºä¿ default_box æ˜¯å­—å…¸ä¸”åŒ…å«åº§æ¨™
            if default_box and isinstance(default_box, dict) and 'left' in default_box:
                default_coords = (
                    default_box['left'],
                    default_box['top'],
                    default_box['width'],
                    default_box['height']
                )
            
            # â˜…â˜…â˜… é—œéµä¿®æ­£ â˜…â˜…â˜…
            # return_type='box' : è®“å®ƒå›å‚³åº§æ¨™å­—å…¸ {'left':10, 'top':20...} 
            # è€Œä¸æ˜¯å›å‚³åœ–ç‰‡ Image Object
            box_data = st_cropper(
                st.session_state.resized_image, 
                realtime_update=True,
                box_color='#0000FF',
                aspect_ratio=None,
                default_coords=default_coords,
                return_type='box',  # é€™æ˜¯è§£æ±º TypeError çš„é—œéµ
                key=f"cropper_{current_mode}" 
            )
            
            if box_data:
                st.session_state.zones[current_mode] = box_data

        # æƒ…æ³ 2: é¡¯ç¤ºçµæœ
        elif st.session_state.result_image is not None:
            st.image(st.session_state.result_image, caption="æœ€çµ‚è¾¨è­˜çµæœ (ç´…æ¡†)", use_container_width=True)
            
        # æƒ…æ³ 3: é¡¯ç¤ºåŸåœ– (é è¦½æ¨¡å¼)
        else:
            st.image(st.session_state.resized_image, caption="åŸå§‹ç­”æ¡ˆå¡é è¦½", use_container_width=True)
