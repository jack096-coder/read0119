import streamlit as st
from streamlit_cropper import st_cropper
from PIL import Image, ImageDraw
import numpy as np
import cv2
import pandas as pd
import io

# --- å½±åƒè™•ç†å‡½æ•¸å€åŸŸ (OpenCV) ---

def preprocess_image(pil_image):
    """å°‡ PIL åœ–ç‰‡è½‰æ›ç‚º OpenCV æ ¼å¼ä¸¦è½‰ç‚ºç°éš"""
    open_cv_image = np.array(pil_image.convert('RGB'))
    # Convert RGB to BGR
    open_cv_image = open_cv_image[:, :, ::-1].copy()
    gray = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)
    return open_cv_image, gray

def detect_corner_markers(img_crop_bgr):
    """
    åœ¨çµ¦å®šçš„è£åˆ‡å€åŸŸä¸­è¾¨è­˜é»‘è‰²æ–¹å½¢å®šä½é» (A1)
    å›å‚³: æ¯å€‹å®šä½é»çš„ 4 å€‹è§’åº§æ¨™åˆ—è¡¨ [(x1,y1), (x2,y2), (x3,y3), (x4,y4)]
    """
    gray = cv2.cvtColor(img_crop_bgr, cv2.COLOR_BGR2GRAY)
    # äºŒå€¼åŒ–è™•ç†ï¼Œæ‰¾é»‘è‰²å€åŸŸ (é–¾å€¼å¯èƒ½éœ€è¦èª¿æ•´)
    _, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY_INV)
    
    # å°‹æ‰¾è¼ªå»“
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    detected_squares = []
    for cnt in contours:
        # è¨ˆç®—è¼ªå»“é¢ç©ï¼Œéæ¿¾æ‰å¤ªå°çš„é›œè¨Š
        area = cv2.contourArea(cnt)
        if area < 100: # æœ€å°é¢ç©é–¾å€¼ï¼Œä¾å¯¦éš›åœ–ç‰‡èª¿æ•´
            continue
            
        # è¿‘ä¼¼å¤šé‚Šå½¢
        epsilon = 0.04 * cv2.arcLength(cnt, True)
        approx = cv2.approxPolyDP(cnt, epsilon, True)
        
        # å¦‚æœè¿‘ä¼¼çµæœæœ‰ 4 å€‹é ‚é»ï¼Œä¸”æ¥è¿‘æ­£æ–¹å½¢ (å¯åŠ å…¥é•·å¯¬æ¯”åˆ¤æ–·)
        if len(approx) == 4:
            # å–å¾—é€™ 4 å€‹é»çš„åº§æ¨™ä¸¦è½‰ç‚ºåˆ—è¡¨æ ¼å¼
            points = approx.reshape(4, 2).tolist()
            detected_squares.append(points)
            
    return detected_squares

def detect_bubbles(img_crop_bgr):
    """
    åœ¨çµ¦å®šçš„è£åˆ‡å€åŸŸä¸­è¾¨è­˜åœ“å½¢æ°£æ³¡ (A2, A3)
    ä½¿ç”¨éœå¤«åœ“å½¢è®Šæ› (Hough Circle Transform)
    å›å‚³: åœ“å¿ƒèˆ‡åŠå¾‘åˆ—è¡¨ [(x, y, r), ...]
    """
    gray = cv2.cvtColor(img_crop_bgr, cv2.COLOR_BGR2GRAY)
    # é«˜æ–¯æ¨¡ç³Šä»¥é™å™ª
    blurred = cv2.GaussianBlur(gray, (9, 9), 2)
    
    # --- é—œéµåƒæ•¸èª¿æ•´å€ ---
    # dp: ç´¯åŠ å™¨è§£æåº¦èˆ‡å½±åƒè§£æåº¦çš„åæ¯”ã€‚1 è¡¨ç¤ºç›¸åŒè§£æåº¦ã€‚
    # minDist: æ¢æ¸¬åˆ°çš„åœ“å¿ƒä¹‹é–“çš„æœ€å°è·é›¢ã€‚å¤ªå°æœƒå°è‡´å¤šå€‹ç›¸é„°çš„åœ“è¢«åµæ¸¬åˆ°ã€‚
    # param1: Canny é‚Šç·£æª¢æ¸¬çš„é«˜é–¾å€¼ã€‚
    # param2: ç´¯åŠ å™¨é–¾å€¼ã€‚è¶Šå°è¶Šå®¹æ˜“åµæ¸¬åˆ°åœ“ï¼Œä½†ä¹Ÿè¶Šå¤šèª¤å ±ã€‚
    # minRadius/maxRadius: é æœŸçš„åœ“å½¢åŠå¾‘ç¯„åœã€‚éå¸¸é‡è¦ï¼
    rows = gray.shape[0]
    circles = cv2.HoughCircles(
        blurred, 
        cv2.HOUGH_GRADIENT, 
        dp=1.2, 
        minDist=rows / 20, # ä¾æ“šæ°£æ³¡å¯†åº¦èª¿æ•´
        param1=100,
        param2=30,   # æ­¤å€¼è¶Šä½è¶Šæ•æ„Ÿï¼Œéœ€ä¾å¯¦éš›åœ–ç‰‡èª¿æ•´
        minRadius=10, # æœ€å°åŠå¾‘ (åƒç´ )
        maxRadius=35  # æœ€å¤§åŠå¾‘ (åƒç´ )
    )
    
    detected_circles = []
    if circles is not None:
        circles = np.uint16(np.around(circles))
        for i in circles[0, :]:
            # center_x, center_y, radius
            detected_circles.append((int(i[0]), int(i[1]), int(i[2])))
            
    return detected_circles

def draw_results_on_image(pil_image, results, region_offsets):
    """
    å°‡è¾¨è­˜çµæœç•«åœ¨åŸå§‹åœ–ç‰‡ä¸Š (ç”¨æ–¼é¡¯ç¤º)
    results: åŒ…å« A1_value, A2_value ç­‰çš„å­—å…¸
    region_offsets: æ¯å€‹å€åŸŸç›¸å°æ–¼åŸåœ–å·¦ä¸Šè§’çš„åç§»é‡ (x, y)
    """
    img_cv = np.array(pil_image.convert('RGB'))
    img_cv = img_cv[:, :, ::-1].copy() # è½‰ç‚º BGR ä»¥ä¾› OpenCV ç¹ªåœ–

    # ç¹ªè£½ A1 æ–¹å¡Š (ç´…è‰²å¤šé‚Šå½¢)
    if 'A1_value' in results:
        offset_x, offset_y = region_offsets.get('A1', (0, 0))
        for square in results['A1_value']:
            # å°‡ç›¸å°åº§æ¨™åŠ ä¸Šå€åŸŸåç§»é‡ï¼Œè½‰å›çµ•å°åº§æ¨™
            abs_points = np.array(square) + [offset_x, offset_y]
            pts = abs_points.reshape((-1, 1, 2)).astype(np.int32)
            cv2.polylines(img_cv, [pts], True, (0, 0, 255), 2)

    # ç¹ªè£½ A2, A3 åœ“åœˆçš„å¤–åˆ‡ç´…æ¡†
    for region_key in ['A2_value', 'A3_value']:
        if region_key in results:
            region_name = region_key.split('_')[0]
            offset_x, offset_y = region_offsets.get(region_name, (0, 0))
            for (cx, cy, r) in results[region_key]:
                # è¨ˆç®—çµ•å°åº§æ¨™
                abs_cx = cx + offset_x
                abs_cy = cy + offset_y
                # ç•«å¤–åˆ‡æ­£æ–¹å½¢ (ç´…æ¡†)
                top_left = (abs_cx - r, abs_cy - r)
                bottom_right = (abs_cx + r, abs_cy + r)
                cv2.rectangle(img_cv, top_left, bottom_right, (0, 0, 255), 2)
                # é¸æ“‡æ€§ï¼šç•«å‡ºåœ“å¿ƒ
                cv2.circle(img_cv, (abs_cx, abs_cy), 2, (0, 255, 0), 3)

    # A4 ä¸éœ€è¦ç¹ªåœ–ï¼Œå› ç‚ºå®ƒæœ¬èº«å°±æ˜¯ä¸€å€‹æ¡†
    
    # è½‰å› PIL æ ¼å¼ä»¥åœ¨ Streamlit é¡¯ç¤º
    return Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))


# --- Streamlit ä¸»ç¨‹å¼ ---

st.set_page_config(page_title="ç­”æ¡ˆå¡å€åŸŸæ¨™è¨˜èˆ‡è¾¨è­˜å·¥å…·", layout="wide")

# åˆå§‹åŒ– Session State
if 'img_file' not in st.session_state:
    st.session_state.img_file = None
if 'original_image' not in st.session_state:
    st.session_state.original_image = None
# ç”¨æ–¼å„²å­˜æ‰‹å‹•æ¡†é¸çš„å€åŸŸåº§æ¨™ (box: left, top, width, height)
if 'zones' not in st.session_state:
    st.session_state.zones = {'A1': None, 'A2': None, 'A3': None, 'A4': None}
# ç•¶å‰æ­£åœ¨é€²è¡Œæ¡†é¸çš„æ¨¡å¼
if 'cropping_mode' not in st.session_state:
    st.session_state.cropping_mode = None
# å„²å­˜è¾¨è­˜å¾Œçš„æ•¸å€¼çµæœ
if 'recognition_results' not in st.session_state:
    st.session_state.recognition_results = {}
# å„²å­˜å¸¶æœ‰æ¨™è¨˜çµæœçš„æœ€çµ‚åœ–ç‰‡
if 'result_image' not in st.session_state:
    st.session_state.result_image = None

st.title("ğŸ“ ç­”æ¡ˆå¡å€åŸŸæ¨™è¨˜èˆ‡è‡ªå‹•è¾¨è­˜")
st.write("è«‹ä¸Šå‚³ç©ºç™½ç­”æ¡ˆå¡ï¼Œä¾åºæ¨™è¨˜å€åŸŸï¼Œæœ€å¾ŒåŸ·è¡Œè¾¨è­˜ä¸¦åŒ¯å‡ºè³‡æ–™ã€‚")

# å»ºç«‹å·¦å³åˆ†æ¬„
col_left, col_right = st.columns([1, 2])

# --- å·¦å´æ¬„ä½ï¼šæ§åˆ¶é … ---
with col_left:
    st.header("1. ä¸Šå‚³èˆ‡æ“ä½œ")
    uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ç©ºç™½ç­”æ¡ˆå¡ (jpg, png)", type=["jpg", "png", "jpeg"])

    if uploaded_file:
        if st.session_state.img_file != uploaded_file:
            st.session_state.img_file = uploaded_file
            st.session_state.original_image = Image.open(uploaded_file)
            # é‡ç½®ç‹€æ…‹
            st.session_state.zones = {'A1': None, 'A2': None, 'A3': None, 'A4': None}
            st.session_state.cropping_mode = None
            st.session_state.recognition_results = {}
            st.session_state.result_image = None
            
        st.success("åœ–ç‰‡å·²è¼‰å…¥")
        st.markdown("---")
        st.header("2. æ‰‹å‹•æ¨™ç¤ºå€åŸŸ")
        st.info("é»æ“Šä¸‹æ–¹æŒ‰éˆ•ï¼Œåœ¨å³å´åœ–ä¸Šæ‰‹å‹•æ¡†é¸å°æ‡‰å€åŸŸã€‚")

        # å®šç¾©æŒ‰éˆ•çš„å›èª¿å‡½æ•¸ï¼Œè¨­å®šç•¶å‰çš„æ¡†é¸æ¨¡å¼
        def set_crop_mode(mode):
            st.session_state.cropping_mode = mode

        # å€åŸŸ A1
        col_a1_btn, col_a1_stat = st.columns([2, 1])
        col_a1_btn.button("(1) æ¨™ç¤ºå®šä½é»å€åŸŸ A1", on_click=set_crop_mode, args=('A1',), use_container_width=True)
        if st.session_state.zones['A1']: col_a1_stat.success("å·²æ¨™ç¤º")
        
        # å€åŸŸ A2
        col_a2_btn, col_a2_stat = st.columns([2, 1])
        col_a2_btn.button("(2) æ¨™ç¤ºåŸºæœ¬è³‡æ–™å€ A2", on_click=set_crop_mode, args=('A2',), use_container_width=True)
        if st.session_state.zones['A2']: col_a2_stat.success("å·²æ¨™ç¤º")

        # å€åŸŸ A3
        col_a3_btn, col_a3_stat = st.columns([2, 1])
        col_a3_btn.button("(3) æ¨™ç¤ºé¸æ“‡é¡Œå€ A3", on_click=set_crop_mode, args=('A3',), use_container_width=True)
        if st.session_state.zones['A3']: col_a3_stat.success("å·²æ¨™ç¤º")
        
        # å€åŸŸ A4
        col_a4_btn, col_a4_stat = st.columns([2, 1])
        col_a4_btn.button("(4) æ¨™ç¤ºæ‰‹å¯«å€ A4", on_click=set_crop_mode, args=('A4',), use_container_width=True)
        if st.session_state.zones['A4']: col_a4_stat.success("å·²æ¨™ç¤º")

        st.markdown("---")
        st.header("3. åŸ·è¡Œè¾¨è­˜èˆ‡åŒ¯å‡º")

        # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰å€åŸŸéƒ½å·²æ¨™ç¤º
        all_zones_marked = all(st.session_state.zones.values())
        
        start_btn = st.button("é–‹å§‹è¾¨è­˜", disabled=not all_zones_marked, type="primary", use_container_width=True)
        
        if not all_zones_marked:
            st.warning("è«‹å…ˆå®Œæˆä¸Šæ–¹ (1)~(4) çš„å€åŸŸæ¨™ç¤ºã€‚")

        if start_btn and st.session_state.original_image:
            with st.spinner("æ­£åœ¨é€²è¡Œå½±åƒåˆ†æèˆ‡è¾¨è­˜ï¼Œè«‹ç¨å€™..."):
                try:
                    results = {}
                    region_offsets = {} # ç´€éŒ„æ¯å€‹å€åŸŸç›¸å°æ–¼åŸåœ–çš„åç§»é‡
                    full_img_cv = cv2.cvtColor(np.array(st.session_state.original_image.convert('RGB')), cv2.COLOR_RGB2BGR)
                    
                    # --- è™•ç† A1 (å®šä½é») ---
                    box = st.session_state.zones['A1']
                    # æ ¹æ“šæ¡†é¸åº§æ¨™è£åˆ‡åœ–ç‰‡ (æ³¨æ„ numpy slicing æ˜¯ y, then x)
                    crop_a1 = full_img_cv[box['top']:box['top']+box['height'], box['left']:box['left']+box['width']]
                    results['A1_value'] = detect_corner_markers(crop_a1)
                    region_offsets['A1'] = (box['left'], box['top'])

                    # --- è™•ç† A2 (åŸºæœ¬è³‡æ–™åœ“åœˆ) ---
                    box = st.session_state.zones['A2']
                    crop_a2 = full_img_cv[box['top']:box['top']+box['height'], box['left']:box['left']+box['width']]
                    results['A2_value'] = detect_bubbles(crop_a2)
                    region_offsets['A2'] = (box['left'], box['top'])

                    # --- è™•ç† A3 (é¸æ“‡é¡Œåœ“åœˆ) ---
                    box = st.session_state.zones['A3']
                    crop_a3 = full_img_cv[box['top']:box['top']+box['height'], box['left']:box['left']+box['width']]
                    results['A3_value'] = detect_bubbles(crop_a3)
                    region_offsets['A3'] = (box['left'], box['top'])

                    # --- è™•ç† A4 (æ‰‹å¯«å€åº§æ¨™) ---
                    box = st.session_state.zones['A4']
                    # è¨˜éŒ„ A4 çš„ 4 å€‹è§’åº§æ¨™ (å·¦ä¸Š, å³ä¸Š, å³ä¸‹, å·¦ä¸‹)
                    results['A4_value'] = [
                        (box['left'], box['top']),
                        (box['left'] + box['width'], box['top']),
                        (box['left'] + box['width'], box['top'] + box['height']),
                        (box['left'], box['top'] + box['height'])
                    ]

                    st.session_state.recognition_results = results
                    
                    # å°‡çµæœç¹ªè£½åˆ°åœ–ç‰‡ä¸Š
                    result_img_pil = draw_results_on_image(st.session_state.original_image, results, region_offsets)
                    st.session_state.result_image = result_img_pil
                    
                    # è¾¨è­˜å®Œæˆå¾Œï¼Œé€€å‡ºæ¡†é¸æ¨¡å¼ä»¥é¡¯ç¤ºçµæœåœ–
                    st.session_state.cropping_mode = None 
                    st.success(f"è¾¨è­˜å®Œæˆ! æ‰¾åˆ° A1å®šä½é»çµ„: {len(results['A1_value'])}, A2æ°£æ³¡: {len(results['A2_value'])}, A3æ°£æ³¡: {len(results['A3_value'])}")

                except Exception as e:
                    st.error(f"è¾¨è­˜éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")

        # åŒ¯å‡º Excel æŒ‰éˆ•
        if st.session_state.recognition_results:
            # æº–å‚™ Excel è³‡æ–™
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # A1 Sheet
                a1_data = []
                for i, square in enumerate(st.session_state.recognition_results.get('A1_value', [])):
                    row = {'Square_ID': i+1}
                    for j, pt in enumerate(square):
                        row[f'Corner_{j+1}_X'] = pt[0]
                        row[f'Corner_{j+1}_Y'] = pt[1]
                    a1_data.append(row)
                pd.DataFrame(a1_data).to_excel(writer, sheet_name='A1_Markers', index=False)
                
                # A2 Sheet
                a2_data = [{'Bubble_ID': i+1, 'Center_X': c[0], 'Center_Y': c[1], 'Radius': c[2]} 
                           for i, c in enumerate(st.session_state.recognition_results.get('A2_value', []))]
                pd.DataFrame(a2_data).to_excel(writer, sheet_name='A2_Bubbles', index=False)

                # A3 Sheet
                a3_data = [{'Bubble_ID': i+1, 'Center_X': c[0], 'Center_Y': c[1], 'Radius': c[2]} 
                           for i, c in enumerate(st.session_state.recognition_results.get('A3_value', []))]
                pd.DataFrame(a3_data).to_excel(writer, sheet_name='A3_Bubbles', index=False)

                # A4 Sheet
                a4_coords = st.session_state.recognition_results.get('A4_value', [])
                if a4_coords:
                    a4_data = [{
                        'Top_Left_X': a4_coords[0][0], 'Top_Left_Y': a4_coords[0][1],
                        'Bottom_Right_X': a4_coords[2][0], 'Bottom_Right_Y': a4_coords[2][1]
                    }]
                    pd.DataFrame(a4_data).to_excel(writer, sheet_name='A4_Handwriting', index=False)

            output.seek(0)
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰è¾¨è­˜çµæœ Excel",
                data=output,
                file_name="omr_recognition_results.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

# --- å³å´æ¬„ä½ï¼šé¡¯ç¤ºå€åŸŸ ---
with col_right:
    st.header("é è¦½èˆ‡æ“ä½œå€")
    
    if st.session_state.original_image is None:
        st.info("è«‹å…ˆåœ¨å·¦å´ä¸Šå‚³åœ–ç‰‡ã€‚")
    else:
        current_mode = st.session_state.cropping_mode
        
        # å¦‚æœè™•æ–¼ä»»ä½•ä¸€ç¨®æ¡†é¸æ¨¡å¼
        if current_mode in ['A1', 'A2', 'A3', 'A4']:
            st.warning(f"æ­£åœ¨æ¨™ç¤ºå€åŸŸ: **{current_mode}**ã€‚è«‹åœ¨ä¸‹æ–¹åœ–ç‰‡æ‹–æ›³æ»‘é¼ æ¡†é¸ï¼Œå®Œæˆå¾Œè«‹é»æ“Šã€ŒApplyã€æˆ–é›™æ“Šæ»‘é¼ ã€‚")
            
            # å–å¾—ä¹‹å‰å„²å­˜çš„è©²å€åŸŸçš„æ¡† (å¦‚æœæœ‰çš„è©±)ï¼Œä½œç‚ºé è¨­é¡¯ç¤º
            default_box = st.session_state.zones[current_mode]
            box_color = '#0000FF' # è—è‰²æ¡†
            
            # å‘¼å« streamlit-cropper å…ƒä»¶
            cropped_box = st_cropper(
                st.session_state.original_image,
                realtime_update=True,
                box_color=box_color,
                aspect_ratio=None, # ä¸å›ºå®šæ¯”ä¾‹
                default_coords=(default_box['left'], default_box['top'], default_box['width'], default_box['height']) if default_box else None,
                key=f"cropper_{current_mode}" # ä½¿ç”¨ä¸åŒçš„ key å¼·åˆ¶é‡æ–°æ¸²æŸ“å…ƒä»¶
            )
            
            # ç•¶ cropper å›å‚³æ•¸å€¼æ™‚ (ä½¿ç”¨è€…å®Œæˆæ¡†é¸)
            if cropped_box:
                # å°‡æ¡†é¸åº§æ¨™å­˜å…¥ session state
                st.session_state.zones[current_mode] = cropped_box
                # ä¸è‡ªå‹•é€€å‡ºæ¨¡å¼ï¼Œè®“ä½¿ç”¨è€…å¯ä»¥å¾®èª¿ï¼Œç›´åˆ°ä»–å€‘é»æ“Šä¸‹ä¸€å€‹æŒ‰éˆ•
                # st.session_state.cropping_mode = None 
                # st.rerun()

        # å¦‚æœæœ‰è¾¨è­˜çµæœåœ–ï¼Œå„ªå…ˆé¡¯ç¤ºçµæœåœ–
        elif st.session_state.result_image is not None:
            st.image(st.session_state.result_image, caption="è¾¨è­˜çµæœ (ç´…æ¡†ç‚ºè‡ªå‹•åµæ¸¬é …ç›®)", use_container_width=True)
            st.info("è—è‰²æ¡†é¸ç·šå·²ç§»é™¤ï¼Œåœ–ä¸Šé¡¯ç¤ºçš„æ˜¯ OpenCV è¾¨è­˜å‡ºçš„ç´…æ¡†ã€‚")
            
        # å¦å‰‡é¡¯ç¤ºåŸåœ– (éæ¡†é¸æ¨¡å¼ï¼Œä¹Ÿç„¡çµæœæ™‚)
        else:
            st.image(st.session_state.original_image, caption="åŸå§‹åœ–ç‰‡", use_container_width=True)
